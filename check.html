<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Making Large Language Models produce structured output using Guardrails AI</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="check_files/libs/clipboard/clipboard.min.js"></script>
<script src="check_files/libs/quarto-html/quarto.js"></script>
<script src="check_files/libs/quarto-html/popper.min.js"></script>
<script src="check_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="check_files/libs/quarto-html/anchor.min.js"></script>
<link href="check_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="check_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="check_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="check_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="check_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="check_files/libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Making Large Language Models produce structured output using Guardrails AI</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb1" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> textwrap <span class="im">import</span> TextWrapper</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>wrapper <span class="op">=</span> TextWrapper(width<span class="op">=</span><span class="dv">80</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb2" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> openai</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="language-models-are-hard-to-configure-and-control" class="level2">
<h2 class="anchored" data-anchor-id="language-models-are-hard-to-configure-and-control">Language Models are hard to configure and control</h2>
<p>Let’s start with a very simple prompt asking OpenAI’s GPT-3 to add 1+1 and return the answer. In this case, we would like GPT-3 to act as a calculator and return back to us the result.</p>
<p>Note for those not familiar with how to call OpenAI chat completion: the TLDR is you choose a model, send the prompts as history of system, user and assistant messages, along with somple sampling parameters like (<code>top_p</code> or <code>temperature</code>) and then you get back a response which you can parse the assistant message from.</p>
<div class="cell" data-source-line-numbers="6" data-execution_count="52">
<div class="sourceCode cell-code" id="cb3" data-source-line-numbers="6" data-code-line-numbers="6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> openai.ChatCompletion.create(</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>,</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    messages<span class="op">=</span>[</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>            <span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You are a helpful assistant."</span>,</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"Return only the integer answer, 1+1="</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>response[<span class="st">'choices'</span>][<span class="dv">0</span>][<span class="st">"message"</span>][<span class="st">'content'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre data-code-line-numbers=""><code>'The integer answer to 1+1 is 2.'</code></pre>
</div>
</div>
<p>You can see that even though we explicitly stated “Return only the integer answer” expecting only <code>2</code> to be returned, the model chose to return a full sentence string instead, causing all sorts of frustration.</p>
<p>To resolve this naively, we would then go about a “prompt engineering” journey where we try to find the “right prompt template” to get the model to do what we want. This is a very time consuming process and is not scalable.</p>
<p>So the question becomes, when engineering a system that makes use of a language model as one component, how can we enforce control over the output of the model without spending endless cycles tuning prompts ?</p>
<p>There are several approaches to this probelm.</p>
<p>In this article, we will do a deep dive into the <a href="https://guardrailsai.com">guardrails AI</a> approach. The TLDR is the following: guardrails AI - allows us to declare our output schema using familiar tooling like <a href="https://docs.pydantic.dev/latest/">pydantic</a> - provides us with out of the box prompt templates that we can use to get the model to produce the output we want - if the language model fails to produce the output we want, guardrails has out of the box prompt templates to “re-ask the model” to correct its output</p>
</section>
<section id="guardrails-ai-deep-dive" class="level2">
<h2 class="anchored" data-anchor-id="guardrails-ai-deep-dive">Guardrails AI deep dive</h2>
<section id="de-mystifying-the-guardrails-ai-approach-with-a-simple-example" class="level3">
<h3 class="anchored" data-anchor-id="de-mystifying-the-guardrails-ai-approach-with-a-simple-example">De-mystifying the guardrails AI approach with a simple example</h3>
<p>We start with the same simple query</p>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb5" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"""1+1=?"""</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(query)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>1+1=?</code></pre>
</div>
</div>
<p>We now define the desired answer schema using [pydantic]((https://docs.pydantic.dev/latest/). Pydantic relies on python type annotations to define the attributes of a class.</p>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb7" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> IntegerAnswer(BaseModel):</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""The answer to a question."""</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    value: <span class="bu">int</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"The answer to the question."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We then have to define quite a few things to get guardrails AI to work out of the box: - the system (instruction) prompt template - the user prompt template</p>
<p>Call guardrails <code>Guard.from_pydantic</code> to - produce a spec of our pydantic model that can be inserted into the prompt templates</p>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb8" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> guardrails <span class="im">as</span> gd</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>system_instructions <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="st">You are a helpful assistant only capable of communicating with valid JSON, and no other text.</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>user_prompt <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="st">$</span><span class="sc">{query}</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="st">$</span><span class="sc">{gr.complete_json_suffix_v2}</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>guard <span class="op">=</span> gd.Guard.from_pydantic(</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    instructions<span class="op">=</span>system_instructions,</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    prompt<span class="op">=</span>user_prompt,</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    output_class<span class="op">=</span>IntegerAnswer,</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s print the produced system prompt and user prompt to see how the spec is inserted into the templates.</p>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb9" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"system prompt"</span>, guard.instructions)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"user prompt"</span>, guard.prompt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>system prompt 
You are a helpful assistant only capable of communicating with valid JSON, and no other text.

user prompt 
${query}


Given below is XML that describes the information to extract from this document and the tags to extract it into.

&lt;output&gt;
    &lt;integer name="value" description="The answer to the question."/&gt;
&lt;/output&gt;


ONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise.

Here are examples of simple (XML, JSON) pairs that show the expected behavior:
- `&lt;string name='foo' format='two-words lower-case' /&gt;` =&gt; `{'foo': 'example one'}`
- `&lt;list name='bar'&gt;&lt;string format='upper-case' /&gt;&lt;/list&gt;` =&gt; `{"bar": ['STRING ONE', 'STRING TWO', etc.]}`
- `&lt;object name='baz'&gt;&lt;string name="foo" format="capitalize two-words" /&gt;&lt;integer name="index" format="1-indexed" /&gt;&lt;/object&gt;` =&gt; `{'baz': {'foo': 'Some String', 'index': 1}}`

</code></pre>
</div>
</div>
<p>To craft our prompt-templates, we need to get familiarized with Guardrails AI’s prompt templating language.</p>
<ul>
<li>guardrails relies on a <code>${var}</code> syntax</li>
<li>variables like our <code>query</code> can be passed in like so <code>${query}</code></li>
<li>constants like <code>complete_json_suffix_v2</code> reference pre-defined prompt templates which we can find in the Guardrails AI <a href="https://github.com/guardrails-ai/guardrails/blob/main/guardrails/constants.xml">constants.xml</a> file</li>
</ul>
<p>We can see that Guardrails AI has produced the following xml spec from our pydantic model</p>
<div class="sourceCode" id="cb11" data-code-line-numbers=""><pre class="sourceCode xml code-with-copy"><code class="sourceCode xml"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>&lt;<span class="kw">output</span>&gt;</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    &lt;<span class="kw">integer</span><span class="ot"> name=</span><span class="st">"value"</span><span class="ot"> description=</span><span class="st">"The answer to the question."</span>/&gt;</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>&lt;/<span class="kw">output</span>&gt;</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="inspecting-how-guardrail-builds-the-prompt" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-how-guardrail-builds-the-prompt">Inspecting how Guardrail builds the prompt</h3>
<p>Let’s load the <code>constants.xml</code> file and see what the <code>complete_json_suffix_v2</code> template looks like:</p>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb12" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xml.etree.ElementTree <span class="im">as</span> ET</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>tree <span class="op">=</span> ET.parse((Path(gd.<span class="va">__file__</span>).parent <span class="op">/</span> <span class="st">"constants.xml"</span>))</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>root <span class="op">=</span> tree.getroot()</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Now you can access the elements in the XML file</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> child <span class="kw">in</span> root:</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> child.tag <span class="op">==</span> <span class="st">"complete_json_suffix_v2"</span>:</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(child.text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>
Given below is XML that describes the information to extract from this document and the tags to extract it into.

${output_schema}

ONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise.

Here are examples of simple (XML, JSON) pairs that show the expected behavior:
- `&lt;string name='foo' format='two-words lower-case' /&gt;` =&gt; `{'foo': 'example one'}`
- `&lt;list name='bar'&gt;&lt;string format='upper-case' /&gt;&lt;/list&gt;` =&gt; `{"bar": ['STRING ONE', 'STRING TWO', etc.]}`
- `&lt;object name='baz'&gt;&lt;string name="foo" format="capitalize two-words" /&gt;&lt;integer name="index" format="1-indexed" /&gt;&lt;/object&gt;` =&gt; `{'baz': {'foo': 'Some String', 'index': 1}}`
</code></pre>
</div>
</div>
<p>This gives us the same prompt as before but we can see <code>${output_schema}</code> is not populated with a schema yet.</p>
<p>so we can deduce that the Guardrails’s <code>Guard</code> is responsible for: - producing the <code>output_schema</code> from the pydantic model - replacing <code>${output_schema}</code> with the produced schema</p>
<p>Let’s inspect the <code>Guard</code> class to see what it is composed from:</p>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb14" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>gd.Guard?</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>Init signature:
gd.Guard(
    rail: guardrails.rail.Rail,
    num_reasks: int = None,
    base_model: Optional[pydantic.main.BaseModel] = None,
)
Docstring:     
The Guard class.

This class is the main entry point for using Guardrails. It is
initialized from one of the following class methods:

- `from_rail`
- `from_rail_string`
- `from_pydantic`
- `from_string`

The `__call__`
method functions as a wrapper around LLM APIs. It takes in an LLM
API, and optional prompt parameters, and returns the raw output from
the LLM and the validated output.
Init docstring: Initialize the Guard.
File:           ~/.pyenv/versions/3.10.8/envs/structured-output-llm-py310/lib/python3.10/site-packages/guardrails/guard.py
Type:           type
Subclasses:     </code></pre>
</div>
</div>
<p>Every <code>Guard</code> object is composed of:</p>
<ul>
<li>a <code>Rail</code> object</li>
<li>a setting <code>num_reasks</code> for how many attempts to re-ask the model in case of a failure</li>
<li>the pydantic <code>base_model</code></li>
</ul>
<p>Looking at <code>Guard.from_pydantic</code> we can see that it is constructing the <code>Rail</code> object from the base_model</p>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb16" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>psource gd.Guard.from_pydantic</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>    @classmethod
    def from_pydantic(
        cls,
        output_class: BaseModel,
        prompt: Optional[str] = None,
        instructions: Optional[str] = None,
        num_reasks: int = None,
    ) -&gt; "Guard":
        """Create a Guard instance from a Pydantic model and prompt."""
        rail = Rail.from_pydantic(
            output_class=output_class, prompt=prompt, instructions=instructions
        )
        return cls(rail, num_reasks=num_reasks, base_model=output_class)</code></pre>
</div>
</div>
<p>If we construct the <code>Rail</code> object directly, we can see that it builds out the <code>output_schema</code> and updates the prompts for us</p>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb18" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>rail <span class="op">=</span> gd.Rail.from_pydantic(</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    instructions<span class="op">=</span>system_instructions,</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    prompt<span class="op">=</span>user_prompt,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    output_class<span class="op">=</span>IntegerAnswer,</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"system prompt"</span>, rail.instructions)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"user prompt"</span>, rail.prompt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>system prompt 
You are a helpful assistant only capable of communicating with valid JSON, and no other text.

user prompt 
${query}


Given below is XML that describes the information to extract from this document and the tags to extract it into.

&lt;output&gt;
    &lt;integer name="value" description="The answer to the question."/&gt;
&lt;/output&gt;


ONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise.

Here are examples of simple (XML, JSON) pairs that show the expected behavior:
- `&lt;string name='foo' format='two-words lower-case' /&gt;` =&gt; `{'foo': 'example one'}`
- `&lt;list name='bar'&gt;&lt;string format='upper-case' /&gt;&lt;/list&gt;` =&gt; `{"bar": ['STRING ONE', 'STRING TWO', etc.]}`
- `&lt;object name='baz'&gt;&lt;string name="foo" format="capitalize two-words" /&gt;&lt;integer name="index" format="1-indexed" /&gt;&lt;/object&gt;` =&gt; `{'baz': {'foo': 'Some String', 'index': 1}}`

</code></pre>
</div>
</div>
<p>Let’s inspect <code>gd.Rail.from_pydantic</code> more closely</p>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb20" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>psource gd.Rail.from_pydantic</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>    @classmethod
    def from_pydantic(
        cls,
        output_class: BaseModel,
        prompt: Optional[str] = None,
        instructions: Optional[str] = None,
        reask_prompt: Optional[str] = None,
        reask_instructions: Optional[str] = None,
    ):
        xml = generate_xml_code(
            output_class=output_class,
            prompt=prompt,
            instructions=instructions,
            reask_prompt=reask_prompt,
            reask_instructions=reask_instructions,
        )
        return cls.from_xml(xml)</code></pre>
</div>
</div>
<p>It relies on a core function called <code>generate_xml_code</code> that will produce XML code from the pydantic model. Here is a the docstring for <code>generate_xml_code</code> - note that it calls the generated XML code - the XML RAIL Spec - RAIL is short for “Reliable AI Language”</p>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb22" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> guardrails.rail <span class="im">import</span> generate_xml_code</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(generate_xml_code.__doc__)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>Generate XML RAIL Spec from a pydantic model and a prompt.

    Parameters: Arguments:
        prompt (str): The prompt for this RAIL spec.
        output_class (BaseModel, optional): The Pydantic model that represents the desired output schema.  Do not specify if using a string schema. Defaults to None.
        instructions (str, optional): Instructions for chat models. Defaults to None.
        reask_prompt (str, optional): An alternative prompt to use during reasks. Defaults to None.
        reask_instructions (str, optional): Alternative instructions to use during reasks. Defaults to None.
        validators (List[Validator], optional): The list of validators to apply to the string schema. Do not specify if using a Pydantic model. Defaults to None.
        description (str, optional): The description for a string schema. Do not specify if using a Pydantic model. Defaults to None.
    </code></pre>
</div>
</div>
</section>
<section id="using-our-built-guard-object-to-prompt-a-language-model" class="level3">
<h3 class="anchored" data-anchor-id="using-our-built-guard-object-to-prompt-a-language-model">Using our built Guard object to prompt a language model</h3>
<p>Next we use the guard object to call our language model.</p>
<section id="happy-path-our-system-is-able-to-parse-the-json-and-return-the-answer." class="level4">
<h4 class="anchored" data-anchor-id="happy-path-our-system-is-able-to-parse-the-json-and-return-the-answer.">Happy Path: Our system is able to parse the JSON and return the answer.</h4>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb24" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> warnings.catch_warnings():</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ignore the GuardrailsAI UserWarning</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    warnings.filterwarnings(<span class="st">"ignore"</span>, category<span class="op">=</span><span class="pp">UserWarning</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    raw_llm_output, validated_output <span class="op">=</span> guard(</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        llm_api<span class="op">=</span>openai.Completion.create,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        prompt_params<span class="op">=</span>{<span class="st">"query"</span>: query},</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        num_reasks<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        engine<span class="op">=</span><span class="st">"text-davinci-003"</span>,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">1024</span>,</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>validated_output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre data-code-line-numbers=""><code>{'value': 2}</code></pre>
</div>
</div>
<p>The guard object’s <code>__call__</code> will perform the following steps: - Update the prompt by replacing any remaining <code>${var}</code> with the appropriate values provided in <code>prompt_params</code> - Call the language model API - Parse the returned output using the schema - If the output doesn’t match the schema - it will proceed to perfrom a corrective action - By default the corrective action is to re-prompt the model asking it to resolve the issue - it will repeat this process until the output matches the schema or until a maximum number of attempts is reached. - The result is returned as both a string and a structured object</p>
</section>
<section id="unhappy-path-our-system-is-able-to-parse-the-json-and-return-the-answer." class="level4">
<h4 class="anchored" data-anchor-id="unhappy-path-our-system-is-able-to-parse-the-json-and-return-the-answer.">UnHappy Path: Our system is able to parse the JSON and return the answer.</h4>
<p>Now let’s mock our language model API to force a failure</p>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb26" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> unittest.mock <span class="im">import</span> MagicMock, patch</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>magic_mock <span class="op">=</span> MagicMock()</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>magic_mock.return_value <span class="op">=</span> {</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"object"</span>: <span class="st">"chat.completion"</span>,</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"choices"</span>: [</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"index"</span>: <span class="dv">0</span>,</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">"text"</span>: <span class="st">'{"value": "the answer is 2"}'</span>,</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">"finish_reason"</span>: <span class="st">"stop"</span>,</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"usage"</span>: {<span class="st">"prompt_tokens"</span>: <span class="dv">18</span>, <span class="st">"completion_tokens"</span>: <span class="dv">12</span>, <span class="st">"total_tokens"</span>: <span class="dv">30</span>},</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> patch(<span class="st">"openai.Completion.create"</span>, magic_mock):</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    warnings.filterwarnings(<span class="st">"ignore"</span>, category<span class="op">=</span><span class="pp">UserWarning</span>)</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    raw_llm_output, validated_output <span class="op">=</span> guard(</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>        llm_api<span class="op">=</span>openai.Completion.create,</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>        prompt_params<span class="op">=</span>{<span class="st">"query"</span>: query},</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>        num_reasks<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>        engine<span class="op">=</span><span class="st">"text-davinci-003"</span>,</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">1024</span>,</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">     "</span>.join(wrapper.wrap(<span class="bu">repr</span>(validated_output))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>SkeletonReAsk(incorrect_value={'value': 'the answer is 2'},
     fail_results=[FailResult(outcome='fail', metadata=None, error_message='JSON does
     not match schema', fix_value=None)])</code></pre>
</div>
</div>
</section>
</section>
<section id="advanced-features-in-guardrails" class="level3">
<h3 class="anchored" data-anchor-id="advanced-features-in-guardrails">Advanced features in guardrails</h3>
<section id="section" class="level4">
<h4 class="anchored" data-anchor-id="section"></h4>
</section>
<section id="unhappy-path-introducing-guardrails-validators-and-on-fail-actions" class="level4">
<h4 class="anchored" data-anchor-id="unhappy-path-introducing-guardrails-validators-and-on-fail-actions">UnHappy Path: Introducing Guardrails validators and on-fail actions</h4>
<p>So what options do we have when the model fails to produce the output we want? Can we customize the corrective action? Can we do this on a per attribute basis?</p>
<p>The answer is yes. We can define a guardrails validator for each attribute in our schema. The validator will be called on the parsed output and will return a boolean indicating whether the output is valid or not. If the output is not valid, we can define an on-fail action to perform. The on-fail action can be one of the <a href="https://docs.guardrailsai.com/concepts/output/#specifying-corrective-actions">following actions</a>:</p>
<ul>
<li><code>reask</code> Reask the LLM to generate an output that meets the quality criteria. The prompt used for reasking contains information about which quality criteria failed, which is auto-generated by the validator.</li>
<li><code>fix</code> Programmatically fix the generated output to meet the quality criteria. E.g. for the formatter two-words, the programatic fix simply takes the first 2 words of the generated string.</li>
<li><code>filter</code> Filter the incorrect value. This only filters the field that fails, and will return the rest of the generated output.</li>
<li><code>refrain</code> Refrain from returning an output. If a formatter has the corrective action refrain, then on failure there will be a None output returned instead of the JSON.</li>
<li><code>noop</code> Do nothing. The failure will still be recorded in the logs, but no corrective action will be taken.</li>
<li><code>exception</code> Raise an exception when validation fails.</li>
<li><code>fix_reask</code> First, fix the generated output deterministically, and then rerun validation with the deterministically fixed output. If validation fails, then perform reasking.</li>
</ul>
<p>Let’s try out the <code>ValidRange</code> validator with an <code>exception</code> on_fail action</p>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb28" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> guardrails.validators <span class="im">import</span> ValidRange</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Answer(BaseModel):</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    value: <span class="bu">int</span> <span class="op">=</span> Field(</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        description<span class="op">=</span><span class="st">"The answer to the question."</span>,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        validators<span class="op">=</span>[ValidRange(<span class="bu">min</span><span class="op">=</span><span class="dv">0</span>, on_fail<span class="op">=</span><span class="st">"exception"</span>)],</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>guard <span class="op">=</span> gd.Guard.from_pydantic(</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    output_class<span class="op">=</span>Answer, prompt<span class="op">=</span>user_prompt, instructions<span class="op">=</span>system_instructions</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If the language model returns a value that is not a positive integer, an exception will be raised. Let’s mock the model to return a negative integer.</p>
<div class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb29" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>magic_mock.return_value <span class="op">=</span> {</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"id"</span>: <span class="st">"chatcmpl-8CazZKUCp8KbiUt49J5x7eINiMlvl"</span>,</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"choices"</span>: [</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>            <span class="st">"index"</span>: <span class="dv">0</span>,</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"text"</span>: <span class="st">'{"value": "-2"}'</span>,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"finish_reason"</span>: <span class="st">"stop"</span>,</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"usage"</span>: {<span class="st">"prompt_tokens"</span>: <span class="dv">18</span>, <span class="st">"completion_tokens"</span>: <span class="dv">12</span>, <span class="st">"total_tokens"</span>: <span class="dv">30</span>},</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> patch(<span class="st">"openai.Completion.create"</span>, magic_mock):</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>        raw_llm_output, validated_output <span class="op">=</span> guard(</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>            llm_api<span class="op">=</span>openai.Completion.create,</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>            prompt_params<span class="op">=</span>{<span class="st">"query"</span>: query},</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>            num_reasks<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>            engine<span class="op">=</span><span class="st">"text-davinci-003"</span>,</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>            max_tokens<span class="op">=</span><span class="dv">1024</span>,</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>            temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="bu">type</span>(e))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>&lt;class 'guardrails.validators.ValidatorError'&gt;</code></pre>
</div>
</div>
<p>As you can see a ValidationError is now raised.</p>
<p>Next we inspect the <code>re-ask</code> on-fail action behavior by mocking our model to first return an invalid answer, and then a valid answer.</p>
<div class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb31" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Answer(BaseModel):</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    value: <span class="bu">int</span> <span class="op">=</span> Field(</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>        description<span class="op">=</span><span class="st">"The answer to the question."</span>,</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>        validators<span class="op">=</span>[ValidRange(<span class="bu">min</span><span class="op">=</span><span class="dv">0</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">10</span>, on_fail<span class="op">=</span><span class="st">"reask"</span>)],</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>guard <span class="op">=</span> gd.Guard.from_pydantic(</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    output_class<span class="op">=</span>Answer, prompt<span class="op">=</span>user_prompt, instructions<span class="op">=</span>system_instructions</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>magic_mock <span class="op">=</span> MagicMock()</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>magic_mock.side_effect <span class="op">=</span> [</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"id"</span>: <span class="st">"chatcmpl-8CazZKUCp8KbiUt49J5x7eINiMlvl"</span>,</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"choices"</span>: [</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>                <span class="st">"index"</span>: <span class="dv">0</span>,</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>                <span class="st">"text"</span>: <span class="st">'{"value": "-2"}'</span>,</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>                <span class="st">"finish_reason"</span>: <span class="st">"stop"</span>,</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">"usage"</span>: {<span class="st">"prompt_tokens"</span>: <span class="dv">18</span>, <span class="st">"completion_tokens"</span>: <span class="dv">12</span>, <span class="st">"total_tokens"</span>: <span class="dv">30</span>},</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">"id"</span>: <span class="st">"chatcmpl-8CazZKUCp8KbiUt49J5x7eINiMlvl"</span>,</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">"choices"</span>: [</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>                <span class="st">"index"</span>: <span class="dv">0</span>,</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>                <span class="st">"text"</span>: <span class="st">'{"value": "2"}'</span>,</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>                <span class="st">"finish_reason"</span>: <span class="st">"stop"</span>,</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">"usage"</span>: {<span class="st">"prompt_tokens"</span>: <span class="dv">18</span>, <span class="st">"completion_tokens"</span>: <span class="dv">12</span>, <span class="st">"total_tokens"</span>: <span class="dv">30</span>},</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> patch(<span class="st">"openai.Completion.create"</span>, magic_mock):</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>    raw_llm_output, validated_output <span class="op">=</span> guard(</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>        llm_api<span class="op">=</span>openai.Completion.create,</span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>        prompt_params<span class="op">=</span>{<span class="st">"query"</span>: query},</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>        num_reasks<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>        engine<span class="op">=</span><span class="st">"text-davinci-003"</span>,</span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">1024</span>,</span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a>validated_output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre data-code-line-numbers=""><code>{'value': 2}</code></pre>
</div>
</div>
<p>Reasking resolved the issue and returned the correct value ! Lets inpsect the reask prompt that was used</p>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb33" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(magic_mock.call_args[<span class="dv">1</span>][<span class="st">"prompt"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>
You are a helpful assistant only capable of communicating with valid JSON, and no other text.

ONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter `null`.

Here are examples of simple (XML, JSON) pairs that show the expected behavior:
- `&lt;string name='foo' format='two-words lower-case' /&gt;` =&gt; `{'foo': 'example one'}`
- `&lt;list name='bar'&gt;&lt;string format='upper-case' /&gt;&lt;/list&gt;` =&gt; `{"bar": ['STRING ONE', 'STRING TWO', etc.]}`
- `&lt;object name='baz'&gt;&lt;string name="foo" format="capitalize two-words" /&gt;&lt;integer name="index" format="1-indexed" /&gt;&lt;/object&gt;` =&gt; `{'baz': {'foo': 'Some String', 'index': 1}}`



I was given the following JSON response, which had problems due to incorrect values.

{
  "value": {
    "incorrect_value": -2,
    "error_messages": [
      "Value -2 is less than 0."
    ]
  }
}

Help me correct the incorrect values based on the given error messages.

Given below is XML that describes the information to extract from this document and the tags to extract it into.

&lt;output&gt;
    &lt;integer name="value" format="valid-range: min=0 max=10" description="The answer to the question."/&gt;
&lt;/output&gt;


ONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter `null`.


Json Output:

</code></pre>
</div>
</div>
<p>Note that for some reason Guardrails AI doesn’t chose to add the initial query 1+1=? to the prompt which is strange given it should be important context for the model.</p>
<p>If instead we used <code>fix</code> instead of <code>reask</code> then validator will try to coerce a value of 0 or 10 depending on which is closer</p>
<div class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb35" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Answer(BaseModel):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    value: <span class="bu">int</span> <span class="op">=</span> Field(</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>        description<span class="op">=</span><span class="st">"The answer to the question."</span>,</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>        validators<span class="op">=</span>[ValidRange(<span class="bu">min</span><span class="op">=</span><span class="dv">0</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">10</span>, on_fail<span class="op">=</span><span class="st">"fix"</span>)],</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>guard <span class="op">=</span> gd.Guard.from_pydantic(</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    output_class<span class="op">=</span>Answer, prompt<span class="op">=</span>user_prompt, instructions<span class="op">=</span>system_instructions</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>magic_mock <span class="op">=</span> MagicMock()</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>magic_mock.return_value <span class="op">=</span> {</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"id"</span>: <span class="st">"chatcmpl-8CazZKUCp8KbiUt49J5x7eINiMlvl"</span>,</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"choices"</span>: [</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">"index"</span>: <span class="dv">0</span>,</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">"text"</span>: <span class="st">'{"value": "-2"}'</span>,</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">"finish_reason"</span>: <span class="st">"stop"</span>,</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">"usage"</span>: {<span class="st">"prompt_tokens"</span>: <span class="dv">18</span>, <span class="st">"completion_tokens"</span>: <span class="dv">12</span>, <span class="st">"total_tokens"</span>: <span class="dv">30</span>},</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> patch(<span class="st">"openai.Completion.create"</span>, magic_mock):</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>    raw_llm_output, validated_output <span class="op">=</span> guard(</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>        llm_api<span class="op">=</span>openai.Completion.create,</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>        prompt_params<span class="op">=</span>{<span class="st">"query"</span>: query},</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>        num_reasks<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>        engine<span class="op">=</span><span class="st">"text-davinci-003"</span>,</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">1024</span>,</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(validated_output)</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>magic_mock.return_value <span class="op">=</span> {</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>    <span class="st">"id"</span>: <span class="st">"chatcmpl-8CazZKUCp8KbiUt49J5x7eINiMlvl"</span>,</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>    <span class="st">"choices"</span>: [</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a>            <span class="st">"index"</span>: <span class="dv">0</span>,</span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a>            <span class="st">"text"</span>: <span class="st">'{"value": "14"}'</span>,</span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a>            <span class="st">"finish_reason"</span>: <span class="st">"stop"</span>,</span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a>    <span class="st">"usage"</span>: {<span class="st">"prompt_tokens"</span>: <span class="dv">18</span>, <span class="st">"completion_tokens"</span>: <span class="dv">12</span>, <span class="st">"total_tokens"</span>: <span class="dv">30</span>},</span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> patch(<span class="st">"openai.Completion.create"</span>, magic_mock):</span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a>    raw_llm_output, validated_output <span class="op">=</span> guard(</span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a>        llm_api<span class="op">=</span>openai.Completion.create,</span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a>        prompt_params<span class="op">=</span>{<span class="st">"query"</span>: query},</span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a>        num_reasks<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a>        engine<span class="op">=</span><span class="st">"text-davinci-003"</span>,</span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">1024</span>,</span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(validated_output)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>{'value': '0'}
{'value': '10'}</code></pre>
</div>
</div>
<p>And if we use <code>filter</code> as the corrective action will return an empty dictionary given we only inspect one key named “value”</p>
<div class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb37" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Answer(BaseModel):</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    value: <span class="bu">int</span> <span class="op">=</span> Field(</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>        description<span class="op">=</span><span class="st">"The answer to the question."</span>,</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>        validators<span class="op">=</span>[ValidRange(<span class="bu">min</span><span class="op">=</span><span class="dv">0</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">10</span>, on_fail<span class="op">=</span><span class="st">"filter"</span>)],</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>guard <span class="op">=</span> gd.Guard.from_pydantic(</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    output_class<span class="op">=</span>Answer, prompt<span class="op">=</span>user_prompt, instructions<span class="op">=</span>system_instructions</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>magic_mock <span class="op">=</span> MagicMock()</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>magic_mock.return_value <span class="op">=</span> {</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"id"</span>: <span class="st">"chatcmpl-8CazZKUCp8KbiUt49J5x7eINiMlvl"</span>,</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"choices"</span>: [</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">"index"</span>: <span class="dv">0</span>,</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">"text"</span>: <span class="st">'{"value": "-2"}'</span>,</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">"finish_reason"</span>: <span class="st">"stop"</span>,</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">"usage"</span>: {<span class="st">"prompt_tokens"</span>: <span class="dv">18</span>, <span class="st">"completion_tokens"</span>: <span class="dv">12</span>, <span class="st">"total_tokens"</span>: <span class="dv">30</span>},</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> patch(<span class="st">"openai.Completion.create"</span>, magic_mock):</span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>    raw_llm_output, validated_output <span class="op">=</span> guard(</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>        llm_api<span class="op">=</span>openai.Completion.create,</span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>        prompt_params<span class="op">=</span>{<span class="st">"query"</span>: query},</span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>        num_reasks<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>        engine<span class="op">=</span><span class="st">"text-davinci-003"</span>,</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">1024</span>,</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(validated_output)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre data-code-line-numbers=""><code>{}</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="time-for-a-more-complex-example" class="level2">
<h2 class="anchored" data-anchor-id="time-for-a-more-complex-example">Time for a more complex example</h2>
<section id="routing-between-two-possible-response-schemas" class="level3">
<h3 class="anchored" data-anchor-id="routing-between-two-possible-response-schemas">Routing between two possible response schemas</h3>
<p>For instance if you have a language model that can return more than one possible schema, you can use a choice validator to route between the schemas.</p>
</section>
<section id="complex-validators-out-of-the-box" class="level3">
<h3 class="anchored" data-anchor-id="complex-validators-out-of-the-box">Complex validators out of the box</h3>
<p>For certain cases like checking if the returned output is valid SQL or valid Python, you can use the built-in guardrail validators for these cases.</p>
<p>see the guardrails <a href="https://docs.guardrailsai.com/api_reference/validators/">validators page</a> for more details.</p>
</section>
<section id="custom-validators" class="level3">
<h3 class="anchored" data-anchor-id="custom-validators">Custom validators</h3>
<p>Earlier this year there was a <a href="https://www.youtube.com/watch?v=iWhlrkfJrCQ&amp;ab_channel=GothamChess">popular video of how ChatGPT couldn’t stick to performing legal chess moves</a>. Guardrails AI has an <a href="https://docs.guardrailsai.com/examples/valid_chess_moves/">example in progress</a> of how to use custom validators to enforce a legal chess game.</p>
</section>
<section id="flexibility-of-the-guardrails-approach" class="level3">
<h3 class="anchored" data-anchor-id="flexibility-of-the-guardrails-approach">Flexibility of the guardrails approach</h3>
<p>The guardrails approach is very flexible and can be used to validate any kind of language model.</p>
</section>
<section id="using-guardrails-to-validate-a-gpt2-model-loaded-locally" class="level3">
<h3 class="anchored" data-anchor-id="using-guardrails-to-validate-a-gpt2-model-loaded-locally">Using guardrails to validate a gpt2 model loaded locally</h3>
</section>
<section id="using-guardrails-against-the-anyscale-api" class="level3">
<h3 class="anchored" data-anchor-id="using-guardrails-against-the-anyscale-api">Using guardrails against the anyscale API</h3>
</section>
<section id="weaknesses-of-guardrails" class="level3">
<h3 class="anchored" data-anchor-id="weaknesses-of-guardrails">Weaknesses of Guardrails</h3>
<ul>
<li>Given that guardrails relies on re-prompts to correct the model, it is not suitable for use cases where the model is expensive to call.</li>
<li>Default prompts provided by guardrails might not be optimal for your use case.</li>
</ul>
</section>
<section id="areas-of-improvement" class="level3">
<h3 class="anchored" data-anchor-id="areas-of-improvement">Areas of improvement</h3>
<ul>
<li>Inheriting validators from pydantic models would be nice but support for it is still lacking.</li>
<li>Using different models to perform correction</li>
</ul>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



<script src="check_files/libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>